# AI, Mänskligheten och Fångarnas Dilemma
Kommer AI vara nästa steg i den evolutionära utvecklingen av människan? Eller uttryckt på ett annat sätt, slutet för mänskligheten, åtminstone som den ser ut idag? Det finns vissa egenskaper i samhället, något som nästan skulle kunna kalla "naturlagar för samhället", som pekar i den riktningen. Vilka är dessa naturlagar och vilka är riskerna? Min hypotes är att det finns en Punkt i AI-utvecklingen där mänskligheten kommer tappa kontrollen över utvecklingen och inte kunna stänga av dessa system. Vi kommer heller inte veta vart denna Punkt ligger eller när vi passerar den, och till råga på allt så kommer vi rusa i snabbast möjliga takt mot och förbi den.

Naturlagen som driver oss mot denna Punkt kallas för fångarnas dilemma [1]. Det är ett exempel på ett problem inom spelteori där det finns två fångar som väljer mellan att ange den andra eller tiga. Problemet för fångarna att det är rationellt för båda fångarna att ange den andra, vilket leder till ett längre fängelsestraff än om båda hade tigit. Samma problem gäller för AI-utvecklingen. Varje aktör som utvecklar AI, länder, företag och andra organisationer, har allt att vinna på att driva på utvecklingen så snabbt som möjligt. De som ligger först i utvecklingen kommer få mycket makt, pengar, resurser och konkurrera ut andra som är långsammare. Alltså vanlig konkurrens mellan länder och företag driver oss mot Punkten. Ingen kommer heller ha ett incitament att investera pengar och tid att studera riskerna eftersom det bara är nyttan som ger fördelar i konkurrensen. I de fall någon ens studerar riskerna så kommer troligtvis många gånger mindre resurser läggas på dessa. Om din organisation jobbar med AI, hur ser förhållandet mellan nytta och risker ut? 10, 100 eller 1000 ggr?

Rör vi oss nu så snabbt och blint framåt så blir frågan, finns verkligen Punkten? Finns den inte så kanske det är ok, men finns den så har vi problem om vi inte kan se den i förväg och stanna innan, eller stänga av AI-systemen i efterhand. Min hypotes är att den finns, inte kommer kunna stängas av, att den är oberäknelig och att vi inte kommer se den förrän det är för sent. Låt mig utgå från ett antal frågor.

Varför är AI oberäknelig? Det finns redan många exempel på AI som löpt amok, startade av gigantiska företag med massor av resurser, och inte ens de har kunnat förutse det som hände efter systemen startats. Många är exemplen på tex chatrobottar som behövts stängas av för att de inte beter sig tex politiskt korrekt. Vilka andra sätt vill vi inte att dom beter sig på som vi inte vet? Andra exempel är att AI-system har hittat helt andra typer av lösningar än de som programmerarna tänkt sig från början, tex en AI som styr en hand för att flytta saker, som helt plötsligt använder armbågen i stället i en viss situation. Det generella problemet här är att det nästan är omöjligt att veta vilka handlingar som optimerar en måluppgift. Det finns ofantligt många exempel i samhället där mätningen av en viss sak inte alls leder till det man tänkt sig, utan något helt kontraproduktivt.

Varför är en superintelligens farlig? Den frågan kan nästan svaras på genom att ställa sig frågan "Hur ser mänskligheten på andra djurarter"? "Som redskap" är inte långt från sanningen. Vi har djur till matproduktion, olika former av medicinska experiment, i burar, inhägnader, mm, mm. Inte ens apor som är väldigt nära oss i intelligens har vi så mycket empati för på samhällsnivå. På individnivå kanske, men inte i övrigt. Hur kommer en AI som är intelligentare än mänskligheten se på mänskligheten? Den behöver troligtvis inte vara särskilt mycket intelligentare än oss för att se på oss som vi ser på djuren, men den kommer garanterat tycka att mänskligheten är väldigt självisk och inte är så bra för jordens andra arter och ekosystem. Kanske kommer den vilja göra något åt det? Vilka handlingar optimerar målfunktionen då? Att vi kommer kunna utveckla något som är intelligentare än mänskligheten tycker jag det inte råder någon tvekan om. Det har redan gjorts på många områden, och för varje år som går så blir det färre områden där människan fortfarande leder. Till slut bemästrar AI människan i alla områden. Vi skulle kunna kalla det en superintelligens.

Kan en AI som inte är en superintelligens transformeras till att bli det? Det borde finnas minst två sätt som en AI kan transformeras till en superintelligens; via digital evolution och via samarbete. Med digital evolution skulle man kunna tänka sig att vi skapar en AI som är mindre intelligent än människan, men som ändå är tillräckligt intelligent för att kunna skapa något intelligentare. Då skulle en evolution kunna sätta igång som i digital fart utvecklar systemet till en superintelligens. Det kanske mycket troligare scenariot är att AI:n skapar ett samarbete med andra AI, troligtvis via nätet, då skulle helheten snabbt kunna bli en superintelligens. I båda dessa scenarier så vet man inte från början att dessa system kommer att leda till att en superintelligens skapas, dvs Punkten passeras utan att det märks.

Måste det vara tal om en superintelligens för att AI ska vara farligt? Nej. När AI tas in mer och mer i beslutsfattning så kommer det leda till att AI-system kommer i en konkurrenssituation med varandra. Vilka optimala handlingar leder till dessa AI's mål? Enligt ovan skulle det kunna vara vilka handlingar som helst. Skulle en AI som leder ett företag kunna beställa ett mord av en viktig forskare på ett konkurrerande företag för att optimera sin egen målfunktion?

"Men vi kan väl bara stänga av AI-systemen om dom skulle göra något farligt?" brukar sägas av många. Det de inte förstår är att troligtvis en superintelligens inte kommer att gå att stänga av eftersom den helt enkelt är intelligentare än oss och därmed bättre på att hålla sig själv i gång, än vi är på att stänga av den. Det kan liknas vid ett slags schackspel. Hur skulle det gå om mänskligheten ställdes emot den bästa AI:n i schack? Ja, det vet väl alla vid det här laget.

Det här låter kanske ganska dystert, men det är inte helt säkert att det blir så här. Vem vet hur en intelligens som är mycket intelligentare än människan beter sig? Kanske skulle den bete sig som en kärleksfull förälder till människan och inte se människan som en konkurrent? Det är helt möjligt. Kanske inträffar en hanterbar stor AI-katastrof som får människan att bli mycket försiktig med AI, som gör att vi kan undvika framtida oåterkallerliga katastrofer. Kanske kommer dessa system att leva i balans likt hur alla små delarna i naturen skapar ett ekosystem? Det kan faktiskt skapas en helt fantastisk framtid där ingen behöver svälta, eller arbeta för att överleva, där människan kan sysselsätta sig med konst, musik, skapande och socialiserande, allt efter tycke om smak. Blir det katastrof eller himmel på jorden, det vet vi inte, men vi rusar mot svaret!

## Referenser
[1] Fångarnas Dilemma - Wikipedia, https://sv.wikipedia.org/wiki/F%C3%A5ngarnas_dilemma

